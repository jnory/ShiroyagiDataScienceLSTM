{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(151)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/Gourmet.json\") as fp:\n",
    "    data = json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[\"train\"]\n",
    "test = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辞書の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wdic = {}\n",
    "wdic_inv = [\"</s>\"]\n",
    "wdic[\"</s>\"] = 0\n",
    "\n",
    "count = 1\n",
    "for words in train:\n",
    "    for w in words:\n",
    "        if w not in wdic:\n",
    "            wdic[w] = count\n",
    "            wdic_inv.append(w)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(wdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語IDに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "for words in train:\n",
    "    ids = []\n",
    "    for w in words:\n",
    "        ids.append(wdic[w])\n",
    "    ids.append(wdic[\"</s>\"])\n",
    "    train_ids.append(ids)\n",
    "\n",
    "test_ids = []\n",
    "for words in test:\n",
    "    ids = []\n",
    "    for w in words:\n",
    "        ids.append(wdic.get(w, 0))\n",
    "    ids.append(wdic[\"</s>\"])\n",
    "    test_ids.append(ids)\n",
    "    \n",
    "train_ids = pad_sequences(train_ids, padding=\"post\", value=wdic[\"</s>\"])\n",
    "test_ids = pad_sequences(test_ids, padding=\"post\", value=wdic[\"</s>\"], maxlen=train_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids.shape, test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasで読み込める形に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train_ids[:, :-1]\n",
    "train_y = to_categorical(train_ids[:, 1:]).reshape((train_ids.shape[0], train_ids.shape[1] - 1, -1))\n",
    "test_x = test_ids[:, :-1]\n",
    "test_y = to_categorical(test_ids[:, 1:], nb_classes=train_y.shape[2]).reshape((test_ids.shape[0], test_ids.shape[1] - 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Activation, LSTM, Dropout, Embedding, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(wdic)+1, 100, mask_zero=True))\n",
    "model.add(LSTM(output_dim=100, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(TimeDistributed(Dense(len(wdic), activation=\"softmax\")))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(train_x, train_y, batch_size=100, nb_epoch=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みデータをロードします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常、このようなモデルは学習に数時間以上(試行錯誤も含めると数日以上)かかるため、モデルを学習しておきました。学習済みモデルをロードして挙動を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hiden = keras.models.load_model(\"data/hiden_no_tare_enshu3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次の単語を予測してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = hiden.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in np.random.choice((test_x.shape[0]), 10):\n",
    "    print(\"*** {} ***\".format(i))\n",
    "    words = []\n",
    "    for wid in pred[i]:\n",
    "        words.append(wdic_inv[wid])\n",
    "        if len(words) >= len(test[i]):\n",
    "            break\n",
    "    df = pd.DataFrame(dict(t=test[i], y=words)).T\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トップ10以内に正解が入る割合はどの程度あるでしょうか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_one(ans, dist, n=10):\n",
    "    top_n_wid = np.argsort(dist)[-n:]\n",
    "    ans_wid = wdic.get(ans, 0)\n",
    "    if ans_wid in top_n_wid:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def evaluate_line(target, line_pred):\n",
    "    total = 0\n",
    "    match = 0\n",
    "    for i, dist in enumerate(line_pred):\n",
    "        if i + 1 < len(target):\n",
    "            total += 1\n",
    "            if evaluate_one(target[i + 1], dist):\n",
    "                match += 1\n",
    "    rate = match / total if total > 0 else 1\n",
    "    return total, match, rate\n",
    "\n",
    "def evaluate(data_x, corpus):\n",
    "    pred_dists = hiden.predict(data_x)\n",
    "    t = 0\n",
    "    m = 0\n",
    "    r = 0.0\n",
    "    for i, line_pred in enumerate(pred_dists):\n",
    "        total, match, rate = evaluate_line(corpus[i], line_pred)\n",
    "        t += total\n",
    "        m += match\n",
    "        r += rate\n",
    "    return m / t * 100, r / pred_dists.shape[0] * 100\n",
    "\n",
    "acc, ave_acc = evaluate(train_x, train)\n",
    "print(\"Acc (Train): {} %\".format(acc))\n",
    "print(\"AveAcc (Train): {} %\".format(ave_acc))\n",
    "acc, ave_acc = evaluate(test_x, test)\n",
    "print(\"Acc (Test): {} %\".format(acc))\n",
    "print(\"AveAcc (Test): {} %\".format(ave_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
