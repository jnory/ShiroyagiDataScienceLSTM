{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(151)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/Gourmet.json\") as fp:\n",
    "    data = json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[\"train\"]\n",
    "test = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['さらに', '肉', 'が', '厚い', '。']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辞書の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wdic = {}\n",
    "wdic_inv = [\"</s>\"]\n",
    "wdic[\"</s>\"] = 0\n",
    "\n",
    "count = 1\n",
    "for words in train:\n",
    "    for w in words:\n",
    "        if w not in wdic:\n",
    "            wdic[w] = count\n",
    "            wdic_inv.append(w)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語IDに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K2 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5110)\n",
      "/opt/anaconda/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "for words in train:\n",
    "    ids = []\n",
    "    for w in words:\n",
    "        ids.append(wdic[w])\n",
    "    ids.append(wdic[\"</s>\"])\n",
    "    train_ids.append(ids)\n",
    "\n",
    "test_ids = []\n",
    "for words in test:\n",
    "    ids = []\n",
    "    for w in words:\n",
    "        ids.append(wdic.get(w, 0))\n",
    "    ids.append(wdic[\"</s>\"])\n",
    "    test_ids.append(ids)\n",
    "    \n",
    "train_ids = pad_sequences(train_ids, padding=\"post\", value=wdic[\"</s>\"])\n",
    "test_ids = pad_sequences(test_ids, padding=\"post\", value=wdic[\"</s>\"], maxlen=train_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 75), (178, 75))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids.shape, test_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasで読み込める形に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train_ids[:, :-1]\n",
    "train_y = to_categorical(train_ids[:, 1:]).reshape((train_ids.shape[0], train_ids.shape[1] - 1, -1))\n",
    "test_x = test_ids[:, :-1]\n",
    "test_y = to_categorical(test_ids[:, 1:], nb_classes=train_y.shape[2]).reshape((test_ids.shape[0], test_ids.shape[1] - 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 74), (710, 74, 2389), (178, 74), (178, 74, 2389))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Activation, LSTM, Dropout, Embedding, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(wdic)+1, 100, mask_zero=True))\n",
    "model.add(LSTM(output_dim=100, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(TimeDistributed(Dense(len(wdic), activation=\"softmax\")))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 639 samples, validate on 71 samples\n",
      "Epoch 1/10\n",
      "639/639 [==============================] - 2s - loss: 7.7713 - acc: 0.0457 - val_loss: 7.7488 - val_acc: 0.0942\n",
      "Epoch 2/10\n",
      "639/639 [==============================] - 2s - loss: 7.6962 - acc: 0.0805 - val_loss: 7.5587 - val_acc: 0.0356\n",
      "Epoch 3/10\n",
      "639/639 [==============================] - 2s - loss: 7.4398 - acc: 0.0410 - val_loss: 7.1325 - val_acc: 0.0358\n",
      "Epoch 4/10\n",
      "639/639 [==============================] - 2s - loss: 7.0695 - acc: 0.0445 - val_loss: 6.6505 - val_acc: 0.0219\n",
      "Epoch 5/10\n",
      "639/639 [==============================] - 2s - loss: 6.6974 - acc: 0.0505 - val_loss: 6.3038 - val_acc: 0.0226\n",
      "Epoch 6/10\n",
      "639/639 [==============================] - 2s - loss: 6.3966 - acc: 0.0562 - val_loss: 6.1649 - val_acc: 0.0257\n",
      "Epoch 7/10\n",
      "639/639 [==============================] - 2s - loss: 6.1732 - acc: 0.0721 - val_loss: 6.1655 - val_acc: 0.0259\n",
      "Epoch 8/10\n",
      "639/639 [==============================] - 2s - loss: 6.0194 - acc: 0.0975 - val_loss: 6.2442 - val_acc: 0.0259\n",
      "Epoch 9/10\n",
      "639/639 [==============================] - 2s - loss: 5.9138 - acc: 0.1636 - val_loss: 6.3593 - val_acc: 0.0396\n",
      "Epoch 10/10\n",
      "639/639 [==============================] - 2s - loss: 5.8586 - acc: 0.2657 - val_loss: 6.4819 - val_acc: 0.7710\n",
      "CPU times: user 36.7 s, sys: 13.5 s, total: 50.2 s\n",
      "Wall time: 50.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb15284f7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_x, train_y, batch_size=100, nb_epoch=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みデータをロードします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常、このようなモデルは学習に数時間以上(試行錯誤も含めると数日以上)かかるため、モデルを学習しておきました。学習済みモデルをロードして挙動を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hiden = keras.models.load_model(\"data/hiden_no_tare_enshu3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次の単語を予測してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "pred = hiden.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 74)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 65 ***\n",
      "   0   1   2  3  4     5  6   7  8    9     10 11  12  13 14  15  16    17   18 19 20  21    22\n",
      "t  つゆ   を  つけ  ず  、  そのまま  で  食べ  て    も  おいしい  し   、  つゆ  や  その  薬味  とともに  食べる  の  も  いい     。\n",
      "y  食べ  種類   て  て  「     「  も   に  も  やっと     ー  た  いい  いい  も  ない  ない    ない   ない  。  。   。  </s>\n",
      "*** 57 ***\n",
      "  0    1    2   3   4   5   6  7  8  9    10 11 12  13  14    15\n",
      "t  心    の   広い  友人  たち   を  持っ  て  い  て  よかっ  た  と  思っ   た     。\n",
      "y  の  食生活  食生活   と   を  食べ   た  き  た  、    た  ば  ば   て  ので  </s>\n",
      "*** 67 ***\n",
      "    0   1     2     3   4  5  6  7\n",
      "t  泣く   子     も    黙る   ３  斤  だ  ！\n",
      "y  食べ  食べ  たこ焼き  たこ焼き  種類  ６  ！  ！\n",
      "*** 52 ***\n",
      "   0   1  2    3  4    5   6  7     8\n",
      "t  私  たち  は  感づい  て  しまい  まし  た     。\n",
      "y  は   が  、    、  も    、   た  。  </s>\n",
      "*** 61 ***\n",
      "      0    1  2    3   4  5     6\n",
      "t    まず  小麦粉  を  こぼし  まし  た     。\n",
      "y  炭水化物    が  生    生   た  。  </s>\n",
      "*** 48 ***\n",
      "   0   1  2  3    4    5  6   7  8   9       10 11 12  13 14  15 16   17 18    19    20\n",
      "t  これ  画像  で  は  分かり  にくい  ん  です  が  実は  チャーシュー  の  下   に  は  大量  の  もやし  が     …     。\n",
      "y   が   の  は  、    、    、  に   が  、   、       。  。  を  ある  、   な  に   ある  、  </s>  </s>\n",
      "*** 142 ***\n",
      "   0  1  2  3  4\n",
      "t  １  ６  ８  ０  円\n",
      "y  コ  ０  ０  円  で\n",
      "*** 88 ***\n",
      "   0  1\n",
      "t  生  協\n",
      "y  と  を\n",
      "*** 98 ***\n",
      "  0  1  2   3   4  5   6  7  8  9  10  11 12 13  14  15  16 17 18  19  20  21 22  23  24  25   26    27 28          29  30  31    32  33  34  35      36  37 38 39    40\n",
      "t  ９  ９  の  やつ  より  は  業務  用  の  が  、  業務  用  の  より   は  平和  堂  の   が   、  平和  堂   の  より   は  セブン  イレブン  の  ホームメイドテイスト   が   、  セブイレ   の  より   は  トロピカーナ  です  か  ね     。\n",
      "y  ８  私  万   に   に  生   生  の  中  に  人   人  の  中   は  ない  ない  に  っ  ない  ここ  ここ  で  だろ   で  追加   追加    追加  れ           れ  追加  機能    機能  だろ   な  だろ      だろ   ね  。  。  </s>\n",
      "*** 51 ***\n",
      "    0  1  2    3  4  5\n",
      "t  昨日  の  お  買い物  で  ！\n",
      "y   は  は  店    店  は  は\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice((test_x.shape[0]), 10):\n",
    "    print(\"*** {} ***\".format(i))\n",
    "    words = []\n",
    "    for wid in pred[i]:\n",
    "        words.append(wdic_inv[wid])\n",
    "        if len(words) >= len(test[i]):\n",
    "            break\n",
    "    df = pd.DataFrame(dict(t=test[i], y=words)).T\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トップ10以内に正解が入る割合はどの程度あるでしょうか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (Train): 83.57603686635944 %\n",
      "AveAcc (Train): 84.69880217063512 %\n",
      "Acc (Test): 32.14831804281346 %\n",
      "AveAcc (Test): 34.3718088856541 %\n"
     ]
    }
   ],
   "source": [
    "def evaluate_one(ans, dist, n=10):\n",
    "    top_n_wid = np.argsort(dist)[-n:]\n",
    "    ans_wid = wdic.get(ans, 0)\n",
    "    if ans_wid in top_n_wid:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def evaluate_line(target, line_pred):\n",
    "    total = 0\n",
    "    match = 0\n",
    "    for i, dist in enumerate(line_pred):\n",
    "        if i + 1 < len(target):\n",
    "            total += 1\n",
    "            if evaluate_one(target[i + 1], dist):\n",
    "                match += 1\n",
    "    rate = match / total if total > 0 else 1\n",
    "    return total, match, rate\n",
    "\n",
    "def evaluate(data_x, corpus):\n",
    "    pred_dists = hiden.predict(data_x)\n",
    "    t = 0\n",
    "    m = 0\n",
    "    r = 0.0\n",
    "    for i, line_pred in enumerate(pred_dists):\n",
    "        total, match, rate = evaluate_line(corpus[i], line_pred)\n",
    "        t += total\n",
    "        m += match\n",
    "        r += rate\n",
    "    return m / t * 100, r / pred_dists.shape[0] * 100\n",
    "\n",
    "acc, ave_acc = evaluate(train_x, train)\n",
    "print(\"Acc (Train): {} %\".format(acc))\n",
    "print(\"AveAcc (Train): {} %\".format(ave_acc))\n",
    "acc, ave_acc = evaluate(test_x, test)\n",
    "print(\"Acc (Test): {} %\".format(acc))\n",
    "print(\"AveAcc (Test): {} %\".format(ave_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
